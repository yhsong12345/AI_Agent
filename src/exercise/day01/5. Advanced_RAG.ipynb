{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def llm_query_rewrite(original_query):\n",
    "    client = OpenAI()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    원본 쿼리: {original_query}\n",
    "    \n",
    "    위 쿼리를 다음 기준으로 다시 작성해주세요:\n",
    "    1. 모호함 제거\n",
    "    2. 관련 키워드 추가\n",
    "    3. 검색에 효과적인 형태로 변환\n",
    "    \n",
    "    다시 작성된 쿼리만 출력하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"OPENAI_DEFAULT_MODEL\"),\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "query = \"인공지능이란 무엇인가?\"\n",
    "print(llm_query_rewrite(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperfocus_rewrite(query, context=None):\n",
    "    \"\"\"\n",
    "    여러 관점에서 쿼리를 재작성하는 하이퍼포커스 기법\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    원본 쿼리: {query}\n",
    "    \n",
    "    이 쿼리에 대한 검색 결과를 최적화하기 위해 다음 5가지 관점에서 쿼리를 재작성해주세요:\n",
    "    1. 정의 관점: 개념이나 용어의 정의를 찾는 쿼리\n",
    "    2. 방법 관점: 특정 작업의 수행 방법을 찾는 쿼리\n",
    "    3. 비교 관점: 여러 항목을 비교하는 쿼리\n",
    "    4. 문제해결 관점: 특정 문제의 해결책을 찾는 쿼리\n",
    "    5. 배경 관점: 주제에 대한 배경 정보를 찾는 쿼리\n",
    "    \n",
    "    각 관점별로 재작성된 쿼리만 나열해주세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"OPENAI_DEFAULT_MODEL\"),\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip().split('\\n')\n",
    "\n",
    "\n",
    "query = \"인공지능이란 무엇인가?\"\n",
    "print(hyperfocus_rewrite(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYDE (Hypothetical Document Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def llm_generate_hypothetical_document(original_query):\n",
    "    \"\"\"\n",
    "    HYDE (Hypothetical Document Embedding)를 위해\n",
    "    주어진 쿼리에 대한 가상의 답변(Hypothetical Document)을 생성합니다.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    # HYDE 프롬프트: 쿼리에 대한 가상의 이상적인 답변을 생성하도록 지시\n",
    "    prompt = f\"\"\"\n",
    "    원본 쿼리: \"{original_query}\"\n",
    "    \n",
    "    위 쿼리에 대해 가장 정확하고 포괄적이며 이상적인 '가상의 답변' 또는 '가상의 문서'를 작성해주세요. \n",
    "    이 답변은 검색 증강 생성(RAG) 시스템에서 임베딩 벡터를 추출하는 데 사용될 것입니다.\n",
    "    따라서, 관련 용어와 상세한 정보를 포함해야 합니다.\n",
    "    \n",
    "    가상의 답변만 출력하고 다른 설명은 포함하지 마세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"OPENAI_DEFAULT_MODEL\"),\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"당신은 사용자 쿼리에 대해 가상의 답변(Hypothetical Document)을 생성하는 유능한 AI입니다.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7, \n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "query = \"인공지능이란 무엇인가?\"\n",
    "hypothetical_doc = llm_generate_hypothetical_document(query)\n",
    "\n",
    "print(f\"**원본 쿼리:** {query}\\n\")\n",
    "print(f\"**HYDE 가상의 답변:**\\n{hypothetical_doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "query = \"인공지능이란 무엇인가?\"\n",
    "documents = [\n",
    "    \"인공지능은 인간의 학습, 추론, 지각 능력을 모방하는 컴퓨터 시스템입니다.\",\n",
    "    \"AI 기술은 머신러닝과 딥러닝을 포함합니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간 언어를 이해하게 합니다.\"\n",
    "]\n",
    "\n",
    "# 각 쿼리-문서 쌍에 대한 점수 계산\n",
    "scores = []\n",
    "for doc in documents:\n",
    "    # 쿼리와 문서를 한 시퀀스로 결합하여 토큰화\n",
    "    inputs = tokenizer(query, doc, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # 점수 계산\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        scores.append(outputs.logits[0].item())  # 관련성 점수 추출\n",
    "\n",
    "# 결과 출력\n",
    "for doc, score in sorted(zip(documents, scores), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"Score: {score:.4f}, Document: {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class LLMReranker:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "        \n",
    "    def rerank(self, query, doc):\n",
    "        results = []\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        [쿼리] {query}\n",
    "        \n",
    "        [문서] {doc}\n",
    "        \n",
    "        위 문서가 쿼리와 얼마나 관련이 있는지 0에서 10 사이의 점수로 평가해주세요.\n",
    "        이유에 대한 설명 없이 숫자만 응답하세요.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=os.getenv(\"OPENAI_DEFAULT_MODEL\"),\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "        )\n",
    "        \n",
    "        score = float(response.choices[0].message.content.strip())\n",
    "        return score\n",
    "    \n",
    "query = \"인공지능이란 무엇인가?\"\n",
    "documents = [\n",
    "    \"인공지능은 인간의 학습, 추론, 지각 능력을 모방하는 컴퓨터 시스템입니다.\",\n",
    "    \"AI 기술은 머신러닝과 딥러닝을 포함합니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간 언어를 이해하게 합니다.\"\n",
    "]\n",
    "\n",
    "scores = []\n",
    "reranker = LLMReranker()\n",
    "\n",
    "scores = []\n",
    "for doc in documents:\n",
    "    scores.append(reranker.rerank(query, doc))\n",
    "\n",
    "for doc, score in sorted(zip(documents, scores), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"Score: {score:.4f}, Document: {doc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
