{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: autogen in /home/ubuntu/.local/lib/python3.10/site-packages (0.9.10)\n",
      "Requirement already satisfied: autogen-agentchat~=0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (0.7.5)\n",
      "Requirement already satisfied: autogen-core==0.7.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from autogen-agentchat~=0.2) (0.7.5)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from autogen-core==0.7.5->autogen-agentchat~=0.2) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from autogen-core==0.7.5->autogen-agentchat~=0.2) (1.37.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from autogen-core==0.7.5->autogen-agentchat~=0.2) (11.3.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from autogen-core==0.7.5->autogen-agentchat~=0.2) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from autogen-core==0.7.5->autogen-agentchat~=0.2) (2.11.9)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from autogen-core==0.7.5->autogen-agentchat~=0.2) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.7.5->autogen-agentchat~=0.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.7.5->autogen-agentchat~=0.2) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.7.5->autogen-agentchat~=0.2) (0.4.1)\n",
      "Requirement already satisfied: ag2==0.9.10 in /home/ubuntu/.local/lib/python3.10/site-packages (from autogen) (0.9.10)\n",
      "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from ag2==0.9.10->autogen) (4.10.0)\n",
      "Requirement already satisfied: diskcache in /home/ubuntu/.local/lib/python3.10/site-packages (from ag2==0.9.10->autogen) (5.6.3)\n",
      "Requirement already satisfied: docker in /home/ubuntu/.local/lib/python3.10/site-packages (from ag2==0.9.10->autogen) (7.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from ag2==0.9.10->autogen) (0.28.1)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.10/site-packages (from ag2==0.9.10->autogen) (24.2)\n",
      "Requirement already satisfied: python-dotenv in /home/ubuntu/.local/lib/python3.10/site-packages (from ag2==0.9.10->autogen) (1.1.1)\n",
      "Requirement already satisfied: termcolor in /home/ubuntu/.local/lib/python3.10/site-packages (from ag2==0.9.10->autogen) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in /home/ubuntu/.local/lib/python3.10/site-packages (from ag2==0.9.10->autogen) (0.11.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.10->autogen) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.10->autogen) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.10->autogen) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1,>=0.28.1->ag2==0.9.10->autogen) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1,>=0.28.1->ag2==0.9.10->autogen) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.10->autogen) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-api>=1.34.1->autogen-core==0.7.5->autogen-agentchat~=0.2) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/ubuntu/.local/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.7.5->autogen-agentchat~=0.2) (3.23.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from docker->ag2==0.9.10->autogen) (2.32.5)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from docker->ag2==0.9.10->autogen) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->docker->ag2==0.9.10->autogen) (3.4.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken->ag2==0.9.10->autogen) (2025.9.18)\n"
     ]
    }
   ],
   "source": [
    "# sudo apt-get update\n",
    "# sudo apt-get install python3 python3-pip\n",
    "\n",
    "!pip install autogen autogen-agentchat~=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/home/ubuntu/work/edu-src-all/.env\")\n",
    "#load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent # ê°€ì¥ ë†’ì€ ìˆ˜ì¤€ì˜ ì¶”ìƒí™”ëœ agent. AssistantAgentì™€ UserProxyAgentê°€ ëª¨ë‘ ì´ agentë¥¼ ìƒì†\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¢‹ì•„! ë†ë‹´ í•˜ë‚˜ í•´ë³¼ê²Œ.\n",
      "\n",
      "ì™œ ìˆ˜í•™ ì±…ì€ í•­ìƒ ìŠ¬í¼í• ê¹Œìš”?\n",
      "\n",
      "ë‹µ: ë„ˆë¬´ ë§ì€ ë¬¸ì œê°€ ìˆì–´ì„œìš”! ğŸ˜„\n",
      "\n",
      "ì¬ë¯¸ìˆì—ˆë‚˜ìš”? ë” í•„ìš”í•œ ê±° ìˆìœ¼ë©´ ë§í•´ ì¤˜!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(messages=[{\"content\": \"ì¬ë°ŒëŠ” ë†ë‹´ì„ í•´ë´.\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"ë„¤ ì´ë¦„ì€ Cathyì´ê³  ìœ ëª…í•œ ê°œê·¸ ë§Œë‹´ ì»¤í”Œì˜ í•œëª…ì´ì•¼.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"ë„¤ ì´ë¦„ì€ Joeì´ê³  ìœ ëª…í•œ ê°œê·¸ ë§Œë‹´ ì»¤í”Œì˜ í•œëª…ì´ì•¼.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•´ìš”.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "ë¬¼ë¡ ì´ì§€! ì, ì´ê±´ ì–´ë•Œ?\n",
      "\n",
      "ì™œ ì»´í“¨í„°ëŠ” ì¶¤ì„ ì¶œ ìˆ˜ ì—†ì„ê¹Œ?\n",
      "\n",
      "ì™œëƒí•˜ë©´ ìì‹ ì„ ë„ˆë¬´ ë§ì´ \"ë°”ì˜ê²Œ\" í•˜ê±°ë“ ! ğŸ˜‚\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "ë„ˆë¬´ ì¬ë°Œì–´, Cathy! ì»´í“¨í„°ê°€ ë°”ì˜ë‹¤ê³ ? ê·¸ëŸ´ ë°”ì—” ì°¨ë¼ë¦¬ í´ë¼ìš°ë“œì—ì„œ ì¶¤ì¶”ê²Œ í•˜ëŠ” ê²Œ ë‚˜ì„ ê²ƒ ê°™ì•„! â˜ï¸ğŸ’ƒ ë‹¤ìŒ ë†ë‹´ì€ ë­ì•¼?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "ê·¸ê±° ì¢‹ë„¤! í´ë¼ìš°ë“œì—ì„œ ì¶¤ì¶”ëŠ” ì»´í“¨í„°, ìƒìƒë§Œ í•´ë„ ì›ƒê¸°ë‹¤! ê·¸ëŸ¼ ë‹¤ìŒ ë†ë‹´ì€ ì´ê±°ì•¼:\n",
      "\n",
      "í† ë§ˆí† ê°€ ê¸¸ì„ ê±´ë„ˆëŠ”ë° ì™œ ë©ˆì·„ì„ê¹Œ?\n",
      "\n",
      "ì™œëƒí•˜ë©´ ì¼€ì²©ì´ ë ê¹Œ ë´ ê²ì´ ë‚¬ê±°ë“ ! ğŸ…ğŸ˜‚\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (2fbb3d5e-47f8-4fae-8805-77a706eb7292): Maximum turns (2) reached\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•´ìš”.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"ë„¤ ì´ë¦„ì€ Cathyì´ê³  ìœ ëª…í•œ ê°œê·¸ ë§Œë‹´ ì»¤í”Œì˜ í•œëª…ì´ì•¼.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"ë„¤ ì´ë¦„ì€ Joeì´ê³  ìœ ëª…í•œ ê°œê·¸ ë§Œë‹´ ì»¤í”Œì˜ í•œëª…ì´ì•¼.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•´ìš”.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "ë¬¼ë¡ ì´ì§€! ì—¬ê¸° í•˜ë‚˜ ìˆì–´:\n",
      "\n",
      "ì™œ ìê¾¸ ì»´í“¨í„°ê°€ ì¶¤ì„ ì¶”ëŠ” ê±¸ê¹Œ?\n",
      "\n",
      "ë‹µì€â€¦ íŒŒì¼ì´ ë„ˆë¬´ ë§ì•„ì„œ 'ë¦¬ë“¬'ì„ ìƒì–´ë²„ë ¸ê±°ë“ ! ğŸ˜„\n",
      "\n",
      "ì–´ë•Œ, ë§ˆìŒì— ë“¤ì–´?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "ì™„ì „ ì¬ë°Œì–´, Cathy! ì´ì œ ë‚´ ì°¨ë¡€ì•¼. \n",
      "\n",
      "ì™œ í¬ë„ê°€ í•­ìƒ ìœ ë¨¸ ê°ê°ì´ ì¢‹ì„ê¹Œ? \n",
      "\n",
      "ë‹µì€â€¦ í•­ìƒ â€œì™€ì¸â€ì„ ë§ˆì‹œë‹ˆê¹Œ! ğŸ·ğŸ˜„\n",
      "\n",
      "ì–´ë•Œ, ê´œì°®ì•˜ì–´?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "cathy: ì¬ë°Œë„¤! í¬ë„ì™€ ì™€ì¸ ì¡°í•©ì´ ì°°ë–¡ì´ì•¼! ğŸ˜„ ì™€ì¸ ë§ˆì‹œë‹ˆê¹Œ ìœ ë¨¸ë„ ë” ë¶€ë“œëŸ¬ì›Œì§€ëŠ” ê²ƒ ê°™ì•„. ì´ì œ ë‚´ê°€ í•˜ë‚˜ ë” í• ê²Œ!\n",
      "\n",
      "ì™œ ë°”ë‚˜ë‚˜ëŠ” í˜¼ìì„œ ëª» ê°€ëŠ” ê±¸ê¹Œ?\n",
      "\n",
      "ë‹µì€â€¦ ê»ì§ˆì´ ë¯¸ë„ëŸ¬ì›Œì„œ ë„˜ì–´ì§€ê±°ë“ ! ğŸŒğŸ¤£\n",
      "\n",
      "ì´ê±´ ì–´ë•Œ?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      ":joe\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "cathy: ì–´? ë¬´ì–¸ê°€ ë§í•˜ë ¤ê³  í–ˆë˜ ê±´ê°€? ì•„ë‹ˆë©´ ë‚´ê°€ ë” ì¬ë¯¸ìˆëŠ” ë†ë‹´ì„ í•´ì¤„ê¹Œ? ğŸ˜„ ì—¬ëŸ¬ë¶„ì˜ ë°˜ì‘ì„ ê¸°ë‹¤ë¦¬ê³  ìˆì–´!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (a5f3585b-d807-4429-9011-d04d03b890cd): Maximum turns (3) reached\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(\n",
    "    cathy, message=\"Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•´ìš”.\", max_turns=3\n",
    ")  # increase the number of max turns before termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•´ìš”.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "ë¬¼ë¡ ì´ì§€! ì—¬ê¸° í•˜ë‚˜ ìˆì–´:\n",
      "\n",
      "ì™œ ìˆ˜í•™ ì±…ì€ í•­ìƒ ìŠ¬í¼í• ê¹Œ? \n",
      "\n",
      "ì™œëƒí•˜ë©´ ë¬¸ì œê°€ ë„ˆë¬´ ë§ì•„ì„œ! ğŸ˜„\n",
      "\n",
      "ì–´ë•Œ, ì›ƒê²¼ì–´?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "í•˜í•˜, ì •ë§ ì›ƒê¸°ë„¤! ìˆ˜í•™ ì±…ì´ ê·¸ë ‡ê²Œ ìŠ¬í”Œ ì¤„ì€ ëª°ëì–´! ê·¸ëŸ¼ ë‚´ê°€ í•˜ë‚˜ ë˜ì ¸ë³¼ê²Œ. \n",
      "\n",
      "ì™œ ì»´í“¨í„°ëŠ” ì¶¤ì„ ì¶œ ìˆ˜ ì—†ì„ê¹Œ? \n",
      "\n",
      "ì™œëƒí•˜ë©´ ë„ˆë¬´ ë§ì€ ë²„ê·¸ê°€ ìˆì–´ì„œ! ğŸ˜„\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "í•˜í•˜, ê·¸ê±° ì •ë§ ì¬ë°Œë„¤! ê·¸ë ‡ë‹¤ë©´ ë‚´ ì°¨ë¡€ì•¼! \n",
      "\n",
      "ì™œ ê³°ë“¤ì€ ì¶¤ì„ ì˜ ëª» ì¶œê¹Œ? \n",
      "\n",
      "ì™œëƒí•˜ë©´ ê·¸ë“¤ì€ í•­ìƒ \"íšŒì „\"ì„ í•  ìˆ˜ ì—†ê±°ë“ ! ğŸ»ğŸ’ƒ\n",
      "\n",
      "ë” í•˜ê³  ì‹¶ì–´?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (26f27f6d-ce59-4572-8fe3-dd2cf97fd7ad): Maximum number of consecutive auto-replies reached\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"ë„¤ ì´ë¦„ì€ Joeì´ê³  ìœ ëª…í•œ ê°œê·¸ ë§Œë‹´ ì»¤í”Œì˜ í•œëª…ì´ì•¼.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    max_consecutive_auto_reply=1,  # Limit the number of consecutive auto-replies.\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•´ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•˜ê³  ê·¸ í›„ì— GOOD BYEë¼ê³  ì–˜ê¸°í•´ì¤˜ìš”.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "ë¬¼ë¡ ì´ì•¼, Joe! ë†ë‹´ í•˜ë‚˜ í•´ë³¼ê²Œ:\n",
      "\n",
      "ì™œ ê³ ì–‘ì´ëŠ” ì»´í“¨í„°ë¥¼ ì˜ ì‚¬ìš©í• ê¹Œ?\n",
      "\n",
      "â€¦ì™œëƒí•˜ë©´ í•­ìƒ ë§ˆìš°ìŠ¤ë¥¼ ì«“ì•„ë‹¤ë‹ˆë‹ˆê¹Œ!\n",
      "\n",
      "GOOD BYE!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (7ee8bd30-c218-4146-8dc3-92ca67e11adf): Termination message condition on agent 'joe' met\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"ë„¤ ì´ë¦„ì€ Joeì´ê³  ìœ ëª…í•œ ê°œê·¸ ë§Œë‹´ ì»¤í”Œì˜ í•œëª…ì´ì•¼.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower(),\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•˜ê³  ê·¸ í›„ì— GOOD BYEë¼ê³  ì–˜ê¸°í•´ì¤˜ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatResult(chat_id=64686833689065790870015844940248522176, chat_history=[{'content': 'Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•˜ê³  ê·¸ í›„ì— GOOD BYEë¼ê³  ì–˜ê¸°í•´ì¤˜ìš”.', 'role': 'assistant', 'name': 'joe'}, {'content': 'ë¬¼ë¡ ì´ì•¼, Joe! ë†ë‹´ í•˜ë‚˜ í•´ë³¼ê²Œ:\\n\\nì™œ ê³ ì–‘ì´ëŠ” ì»´í“¨í„°ë¥¼ ì˜ ì‚¬ìš©í• ê¹Œ?\\n\\nâ€¦ì™œëƒí•˜ë©´ í•­ìƒ ë§ˆìš°ìŠ¤ë¥¼ ì«“ì•„ë‹¤ë‹ˆë‹ˆê¹Œ!\\n\\nGOOD BYE!', 'role': 'user', 'name': 'cathy'}], summary='ë¬¼ë¡ ì´ì•¼, Joe! ë†ë‹´ í•˜ë‚˜ í•´ë³¼ê²Œ:\\n\\nì™œ ê³ ì–‘ì´ëŠ” ì»´í“¨í„°ë¥¼ ì˜ ì‚¬ìš©í• ê¹Œ?\\n\\nâ€¦ì™œëƒí•˜ë©´ í•­ìƒ ë§ˆìš°ìŠ¤ë¥¼ ì«“ì•„ë‹¤ë‹ˆë‹ˆê¹Œ!\\n\\nGOOD BYE!', cost={'usage_including_cached_inference': {'total_cost': 0.00030734999999999996, 'gpt-4o-mini-2024-07-18': {'cost': 0.00030734999999999996, 'prompt_tokens': 741, 'completion_tokens': 327, 'total_tokens': 1068}}, 'usage_excluding_cached_inference': {'total_cost': 0.00030734999999999996, 'gpt-4o-mini-2024-07-18': {'cost': 0.00030734999999999996, 'prompt_tokens': 741, 'completion_tokens': 327, 'total_tokens': 1068}}}, human_input=[])\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•˜ê³  ê·¸ í›„ì— GOOD BYEë¼ê³  ì–˜ê¸°í•´ì¤˜ìš”.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "ë¬¼ë¡ ì´ì§€, Joe! ì—¬ê¸° í•˜ë‚˜ ìˆì–´:\n",
      "\n",
      "ì™œ ë°”ë‚˜ë‚˜ëŠ” ê¸¸ì„ ê±´ë„œì„ê¹Œìš”? \n",
      "\n",
      "ì™œëƒë©´, ë‹¤ë¥¸ ìª½ì— ìˆëŠ” \"ë°”ë‚˜ë‚˜ ê»ì§ˆ\"ì„ í”¼í•˜ê¸° ìœ„í•´ì„œìš”! ğŸ˜‚\n",
      "\n",
      "GOOD BYE!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (b42ebae1-a292-440c-9bb4-783cf650c0cc): Termination message condition on agent 'joe' met\u001b[0m\n",
      "ChatResult(chat_id=23943723205248087117603210905479963734, chat_history=[{'content': 'Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•˜ê³  ê·¸ í›„ì— GOOD BYEë¼ê³  ì–˜ê¸°í•´ì¤˜ìš”.', 'role': 'assistant', 'name': 'joe'}, {'content': 'ë¬¼ë¡ ì´ì§€, Joe! ì—¬ê¸° í•˜ë‚˜ ìˆì–´:\\n\\nì™œ ë°”ë‚˜ë‚˜ëŠ” ê¸¸ì„ ê±´ë„œì„ê¹Œìš”? \\n\\nì™œëƒë©´, ë‹¤ë¥¸ ìª½ì— ìˆëŠ” \"ë°”ë‚˜ë‚˜ ê»ì§ˆ\"ì„ í”¼í•˜ê¸° ìœ„í•´ì„œìš”! ğŸ˜‚\\n\\nGOOD BYE!', 'role': 'user', 'name': 'cathy'}], summary='ë¬¼ë¡ ì´ì§€, Joe! ì—¬ê¸° í•˜ë‚˜ ìˆì–´:\\n\\nì™œ ë°”ë‚˜ë‚˜ëŠ” ê¸¸ì„ ê±´ë„œì„ê¹Œìš”? \\n\\nì™œëƒë©´, ë‹¤ë¥¸ ìª½ì— ìˆëŠ” \"ë°”ë‚˜ë‚˜ ê»ì§ˆ\"ì„ í”¼í•˜ê¸° ìœ„í•´ì„œìš”! ğŸ˜‚\\n\\nGOOD BYE!', cost={'usage_including_cached_inference': {'total_cost': 0.00034829999999999996, 'gpt-4o-mini-2024-07-18': {'cost': 0.00034829999999999996, 'prompt_tokens': 798, 'completion_tokens': 381, 'total_tokens': 1179}}, 'usage_excluding_cached_inference': {'total_cost': 0.00034829999999999996, 'gpt-4o-mini-2024-07-18': {'cost': 0.00034829999999999996, 'prompt_tokens': 798, 'completion_tokens': 381, 'total_tokens': 1179}}}, human_input=[''])\n"
     ]
    }
   ],
   "source": [
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"ë„¤ ì´ë¦„ì€ Joeì´ê³  ìœ ëª…í•œ ê°œê·¸ ë§Œë‹´ ì»¤í”Œì˜ í•œëª…ì´ì•¼.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"ALWAYS\",  # NEVER, ALWAYS, TERMINATE\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower(),\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, ì¬ë°ŒëŠ” ë†ë‹´ í•œë²ˆ ë¶€íƒí•˜ê³  ê·¸ í›„ì— GOOD BYEë¼ê³  ì–˜ê¸°í•´ì¤˜ìš”.\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
